# Comp-Final
I chose the first health related dataset when I was on kaggle that had multiple kinds of values and had a more comprehensive set of features. This may not have been the best choice, I am sure there were other feature/ target variables that I could have used and had better results but the billing amount was to intriguing to pass up. The preporocessing was easy because I only have to look are one column for encoding and choose a float for the target. I did have an incredibly high MSE. This would typically indicate that a linear relationship is incorrect or very weak, it could be outliers, incorrectly scaled data, or most likely poor feature selection as I mentioned earlier. If this was for a project I would go and dig further to see what caused this but I think the purpose of this was to gause coding and comprehension not the validity of the supervised learning algorithm. This is timed so I stayed with what I initailly ran for the sake of time.
